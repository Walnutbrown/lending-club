import sys
import os
import lightgbm as lgb
import warnings
warnings.filterwarnings("ignore")


current_dir = os.path.dirname(os.path.abspath(__file__))
project_dir = os.path.abspath(os.path.join(current_dir, '..', '..'))  # lendingclub_2nd
src_dir = os.path.join(project_dir, 'src')
if src_dir not in sys.path:
    sys.path.insert(0, src_dir)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from utils.make_cashflow import get_cash_flow
from utils.fetch_risk_free_rate import load_risk_free_series, apply_risk_free_rate
from utils.calculate_sharpe import get_irr, calculate_sharpe, precompute_cashflow_and_irr, compute_sharpe_for_threshold

def _attach_cf_irr_and_sharpe_cached(df, threshold):
    df = df.copy()
    df['cash_flow'] = df.apply(
        lambda row: get_cash_flow(row) if row['pred_prob'] <= threshold else np.nan,
        axis=1
    )
    df['irr'] = df['cash_flow'].apply(
        lambda cf: get_irr(cf) if isinstance(cf, list) and len(cf) > 0 else np.nan
    )
    df['irr'] = df['irr'].fillna(df['risk_free_rate'])
    return calculate_sharpe(df['irr'].values, df['risk_free_rate'].values)



def main():
    # 1. ë°ì´í„° ë¡œë”©
    df = pd.read_csv('data/processed/lendingclub_features_for_lightgbm.csv')
    print(f"ğŸ” ì›ë³¸ ë°ì´í„° í¬ê¸°: {df.shape}")

    # ë‚ ì§œ í˜•ì‹ ë³€í™˜
    df['issue_d'] = pd.to_datetime(df['issue_d'], errors = 'coerce')
    df['last_pymnt_d'] = pd.to_datetime(df['last_pymnt_d'], errors = 'coerce')

    # 2. Riskâ€‘free rate ë¶™ì´ê¸° â”€â”€ Sharpe ê³„ì‚°ìš©
    rate_3y, rate_5y = load_risk_free_series()
    df = apply_risk_free_rate(df, rate_3y, rate_5y)

    # 3. ì „ì²˜ë¦¬ ë° ë³€ìˆ˜ í˜¸ì¶œ
    features = pd.read_csv('data/processed/features_final_list_lightgbm.csv')
    features = features['feature'].squeeze().tolist()
    if 'default' in features:
        features.remove('default')

    # object íƒ€ì…ì„ categoryë¡œ ë³€í™˜
    categorical_cols = df.select_dtypes(include='object').columns.tolist()
    for col in categorical_cols:
        df[col] = df[col].astype('category')
    cat_features = [c for c in categorical_cols if c in features]
   
    # 4. ê²°ê³¼ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸
    sharpe_ratios = []
    val_sharpe_ratios = []
    sharpe_at_1 = []

    df_indicies = np.arange(len(df))

    # 5. 100ë²ˆ ë°˜ë³µ
    for seed in range(100):
        # 5-1. ë¬´ì‘ìœ„ ì…”í”Œ
        np.random.seed(seed)
        np.random.shuffle(df_indicies)

        n = len(df)
        train_end = int(n * 0.6)
        val_end = int(n * 0.8)

        train_idx = df_indicies[:train_end]
        val_idx = df_indicies[train_end:val_end]
        test_idx = df_indicies[val_end:]
        
        train = df.iloc[train_idx]
        val = df.iloc[val_idx]
        test = df.iloc[test_idx]
        print(f"ğŸ” Seed {seed}: train={len(train)}, val={len(val)}, test={len(test)}")

        # 5-2. LightGBM ëª¨ë¸ í•™ìŠµ
        X_train = train[features]
        y_train = train['default']
        X_val = val[features]
        y_val = val['default']

        X_test = test[features]
        
        train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=cat_features)
        val_data = lgb.Dataset(X_val, label=y_val, categorical_feature=cat_features)

        params = {
            'objective': 'binary',
            'metric': 'binary_logloss',
            'boosting_type': 'gbdt',
            'verbosity': -1,
            'seed': seed,
        }

        from lightgbm import early_stopping

        model = lgb.train(
            params,
            train_data,
            valid_sets=[train_data, val_data],
            callbacks=[early_stopping(stopping_rounds=30)]
        )

        val['pred_prob']  = model.predict(X_val)
        test['pred_prob'] = model.predict(X_test)
        val  = precompute_cashflow_and_irr(val)
        test = precompute_cashflow_and_irr(test)

        # â”€â”€ â‘  threshold grid search on val â”€â”€
        threshold_grid = np.linspace(0.05, 0.95, 100)   
        val_sharpes = [compute_sharpe_for_threshold(val, th) for th in threshold_grid]
        sharpe1 = compute_sharpe_for_threshold(test, 1)
        sharpe_at_1.append(sharpe1)


        best_idx        = int(np.nanargmax(val_sharpes))
        best_threshold  = threshold_grid[best_idx]
        best_val_sharpe = val_sharpes[best_idx]
        print(f"Seed {seed}: best threshold={best_threshold:.2f}  valâ€‘Sharpe={best_val_sharpe:.4f}")

        # â”€â”€ â‘¡ apply best threshold to test & compute Sharpe â”€â”€
        test_sharpe = _attach_cf_irr_and_sharpe_cached(test, best_threshold)

        sharpe_ratios.append(test_sharpe)
        val_sharpe_ratios.append(best_val_sharpe)

    # 6. ê²°ê³¼ ì‹œê°í™”
    plt.figure(figsize=(10, 6))
    plt.hist(val_sharpe_ratios, bins=30, edgecolor='black')
    plt.title('Distribution of Sharpe Ratios (100 repetitions) â€” validation set')
    plt.xlabel('Sharpe Ratio')
    plt.ylabel('Frequency')
    plt.grid(True)
    plt.show()

    plt.figure(figsize=(10, 6))
    plt.hist(sharpe_ratios, bins=30, edgecolor='black')
    plt.axvline(np.mean(sharpe_at_1), color='red', linestyle='dashed', linewidth=1, label='Sharpe at threshold = 1')
    plt.title('Distribution of Sharpe Ratios (100 repetitions) â€” validation set')
    plt.xlabel('Sharpe Ratio')
    plt.ylabel('Frequency')
    plt.grid(True)
    plt.show()

    # 7. ê²°ê³¼ ì €ì¥
    result_df = pd.DataFrame({'Val Sharpe': val_sharpe_ratios,
                              'Test Sharpe': sharpe_ratios})
    result_df.to_csv('reports/sharpe_distribution_lightgbm.csv', index=False)
    print("ğŸ¯ Sharpe ratio ë¶„í¬ ì €ì¥ ì™„ë£Œ!")

if __name__ == "__main__":
    main()